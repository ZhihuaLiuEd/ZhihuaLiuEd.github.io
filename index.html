<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhihua Liu</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" type="image/png" href="images/seal_icon.png">-->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhihua Liu</name>
              </p>
              <p>
                Greetings! My name is Zhihua Liu (Chinese: 刘志华). I am a Ph.D. student supervised by <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Prof. Huiyu Zhou</a> at the <a href="https://sites.google.com/site/huiyujoe/">Biomedical Image Processing Lab (BIPL)</a>, School of Computing and Mathematical Sciences, University of Leicester. I am funded by the Graduate Teaching Assistantship (GTA), College of Science and Engineering, University of Leicester and China Scholarship Council (CSC).
              </p>
              <p>
                Previously, I served as an algorithm engineer in JD Logistics, JD.com. I received my M.Sc. in Artificial Intelligence from the University of Edinburgh in 2016, my B.Eng. in Internet of Things from University of Science and Technology Beijing in 2015. I spent my undergraduate final year at the School of Computing in University of Dundee, supervised by <a href="http://staff.computing.dundee.ac.uk/stephen/">Prof. Stephen McKenna</a>, <a href="https://www.gla.ac.uk/schools/computing/staff/sebastianstein/">Dr. Sebastian Stein</a> and <a href="https://faculty.sustech.edu.cn/zhangjg/">Prof. Jianguo Zhang</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:zl208@leicester.ac.uk">Email</a> &nbsp/&nbsp
                <a href="data/Zhihua Liu_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=je2KXVYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/Zhihua_L">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/ZhihuaLiuEd">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Zhihua.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Zhihua_Circle.png" class="hoverZoomLink"></a>
              <br>
              <font>Dundee CS Lab, 2014</font>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <ul>
              <li><font color="#FF0000">Mar 2022:</font> Two co-authored paper has been accepted by IEEE Trans. on Neural Networks and Learning Systems and IEEE Trans. on Affective Computing respectively.
              </li>
              <li><font color="#FF0000">Nov 2021:</font> We have finished the extensive revision on <a href="https://arxiv.org/pdf/2007.09479.pdf">"Deep Learning based Brain Tumor Segmentation: A Survey"</a> and opensouced <a href="https://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-Segmentation">the github repo</a>.
              </li>
              
              <li><font color="#FF0000">Oct 2021:</font> It is a great honor for me to invite <a href="https://www.skamalas.com/">Dr.Yannis Kalantidis</a> from NAVER LABS Europe to give a CMS research seminar. 
              </li>


              <li><font color="#FF0000">July 2021:</font> I am very honored to be selected to participate in The PRAIRIE / MIAI Artificial Intelligence Summer School (P.A.I.S.S.) 
                organized by INRIA and the institutes PRAIRIE and MIAI.
              </li>

              <li><font color="#FF0000">Mar 2021:</font> 1 paper has been accepted by IEEE Trans. on Medical Imaging.</li>

              <li><font color="#FF0000">July 2020:</font> I am very honored to be selected to participate in The Medical Image Computing Summer School (MedICSS) at University College London (UCL)
                London, United Kingdom.
              </li>
            </ul>  
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research is focusing on computer vision and machine learning, especially in medical image analysis, unsupervised learning and deep learning.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LSDM.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2301.04748">
              <papertitle>LSDM: Long-Short Diffeomorphic Motion for Weakly-Supervised Ultrasound Landmark Tracking</papertitle>
              </a>
              <br>
              <strong>Zhihua Liu</strong>,
              <a>Bin Yang</a>,
              <a>Yan Shen</a>,
              <a>Xuejun Ni</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>arXiv</em>, 2023 
              <br>
              /
              <a href="https://arxiv.org/pdf/2301.04748.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p> Considering stateof-the-art technologies and their performance, the purpose of this paper is to provide a comprehensive survey of recently developed deep learning based brain tumor segmentation techniques.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/braintumorsurvey.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2007.09479.pdf">
              <papertitle>Deep Learning Based Brain Tumor Segmentation: A Survey</papertitle>
              </a>
              <br>
              <strong>Zhihua Liu</strong>,
              <a>Lei Tong</a>,
              <a>Zheheng Jiang</a>,
              <a>Long Chen</a>,
              <a>Feixiang Zhou</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://scholar.google.co.uk/citations?user=G6AdRfwAAAAJ&hl=en">Xiangrong Zhang</a>,
              <a href="https://scholar.google.co.uk/citations?user=B5WAkz4AAAAJ&hl=en">Yaochu Jin</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>Complex & Intelligent Systems</em>, 2022 
              <br>
              <a href="https://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-Segmentation">code</a>
              /
              <a href="https://arxiv.org/pdf/2007.09479.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>Accurate tracking of an anatomical landmark over time has been of high interests for disease assessment such as minimally invasive surgery and tumor radiation therapy. In this paper, we propose a long-short diffeomorphic motion network, which is a multi-task framework with a learnable deformation prior to search for the plausible deformation of landmark.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mousetrack.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1906.02831.pdf">
              <papertitle>Detecting and Tracking of Multiple Mice Using Part Proposal Networks</papertitle>
              </a>
              <br>
              <a>Zheheng Jiang</a>,
              <strong>Zhihua Liu</strong>,
              <a>Long Chen</a>,
              <a>Lei Tong</a>,
              <a>Xiangrong Zhang</a>,
              <a href="https://www.comp.hkbu.edu.hk/v1/?page=profile&id=lanxiangyuan">Xiangyuan Lan</a>,
              <a href="http://www.cs.qub.ac.uk/~d.crookes/">Danny Crookes</a>,
              <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Neural Networks and Learning Systems</em>, 2022
              <br>
              <a>code</a>
              /
              <a href="https://arxiv.org/pdf/1906.02831.pdf">arXiv</a>
              <p></p>
              <p>A novel method to continuously track several mice and individual parts without requiring any specific tagging.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/twitterdepression.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1906.00398.pdf">
              <papertitle>Cost-sensitive Boosting Pruning Trees for depression detection on Twitter</papertitle>
              </a>
              <br>
              <a>Lei Tong</a>,
              <strong>Zhihua Liu</strong>,
              <a>Zheheng Jiang</a>,
              <a>Feixiang Zhou</a>,
              <a>Long Chen</a>,
              <a>Jialin Lyu</a>,
              <a>Xiangrong Zhang</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://www.brunel.ac.uk/people/abdul-h-sadka/publications">Abdul Sadka</a>,
              <a href="https://scholar.google.com/citations?user=WNY0TscAAAAJ&hl=en">Yinhai Wang</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Affective Computing</em>, 2022 
              <br>
              <a href="https://github.com/BIPL-UoL/Cost-Boosting-Pruning-Trees-for-depression-detection-on-Twitter">code</a>
              /
              <a href="https://arxiv.org/pdf/1906.00398.pdf">arXiv</a>
              <p></p>
              <p>A novel classifier, namely, Cost-sensitive Boosting Pruning Trees (CBPT), which demonstrates a strong classification ability on two publicly accessible Twitter depression detection datasets..</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MPhilThesis.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9378564">
              <papertitle>MPhil Thesis: </papertitle>
              </a>
              <br>
              <strong>Zhihua Liu</strong>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>MPhil Thesis</em>, 2020 
              <br>
              <a href="posters/Zhihua Liu PG Research Day.pdf">Poster</a>
              /
              <a href="">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>Benefited from deep learning techniques, remarkable progress has been made within the medical image analysis area in recent years. However, it is very challenging to fully utilize the relational information (the relationship between tissues or organs or images) within the deep neural network architecture. Thus in this thesis, we propose two novel solutions to this problem called implicit and explicit deep relational learning. We generalize these two paradigms of deep relational learning into different solutions and evaluate them on various medical image analysis tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/canet.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9378564">
              <papertitle>CANet: Context Aware Network for Brain Glioma Segmentation</papertitle>
              </a>
              <br>
              <strong>Zhihua Liu</strong>,
              <a>Lei Tong</a>,
              <a>Long Chen</a>,
              <a>Feixiang Zhou</a>,
              <a>Zheheng Jiang</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a href="https://scholar.google.com/citations?user=WNY0TscAAAAJ&hl=en">Yinhai Wang</a>,
              <a href="https://sites.google.com/site/caifengshan/">Caifeng Shan</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Medical Imaging</em>, 2021 
              <br>
              <a href="https://github.com/ZhihuaLiuEd/canetbrats">code</a>
              /
              <a href="https://arxiv.org/pdf/2007.07788.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>A novel approach named Context-Aware Network (CANet) for brain glioma segmentation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mouse.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2012.00630.pdf">
              <papertitle>Structured Context Enhancement Network for Mouse Pose Estimation</papertitle>
              </a>
              <br>
              <a>Feixiang Zhou</a>,
              <a>Zheheng Jiang</a>,
              <strong>Zhihua Liu</strong>,
              <a>Fang Chen</a>,
              <a>Long Chen</a>,
              <a>Lei Tong</a>,
              <a>Zhile Yang</a>,
              <a>Haikuan Wang</a>,
              <a>Minrui Fei</a>,
              <a href="https://www.kent.ac.uk/computing/people/3061/li-caroline">Ling Li</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Circuits and Systems for Video Technology</em>, 2021 
              <br>
              <a>code</a>
              /
              <a href="https://arxiv.org/pdf/2012.00630.pdf">arXiv</a>
              <!-- /
              <a>video</a>
              /
              <a>demo</a>-->
              <p></p>
              <p>A novel Hourglass network based model, namely Graphical Model based Structured Context Enhancement Network (GMSCENet), quantifies mouse pose estimation from videos.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/longchenTCSVT.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9245532">
              <papertitle>Perceptual underwater image enhancement with deep learning and physical priors</papertitle>
              </a>
              <br>
              <a>Long Chen</a>,
              <a>Zheheng Jiang</a>,
              <a>Lei Tong</a>,
              <strong>Zhihua Liu</strong>,
              <a>Aite Zhao</a>,
              <a href="http://eecs.qmul.ac.uk/profiles/zhangqianni.html">Qianni Zhang</a>,
              <a>Junyu Dong</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>IEEE Trans. on Circuits and Systems for Video Technology</em>, 2020 
              <br>
              <a href="https://github.com/LongChenCV/HybridDetectionGAN">code</a>
              /
              <a href="https://arxiv.org/abs/2008.09697">arXiv</a>
              <p></p>
              <p>In this paper, we propose two perceptual enhancement models, each of which uses a deep enhancement model with a detection perceptor. The detection perceptor provides coherent information in the form of gradients to the enhancement model, guiding the enhancement model to generate patch level visually pleasing images or detection favourable images.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/swipenet.png" alt="Boundary_png" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9207506">
              <papertitle>Underwater object detection using Invert Multi-Class Adaboost with deep learning</papertitle>
              </a>
              <br>
              <a>Long Chen</a>,
              <strong>Zhihua Liu</strong>,
              <a>Lei Tong</a>,
              <a>Zheheng Jiang</a>,
              <a>Shengke Wang</a>,
              <a>Junyu Dong</a>,
              <a href="https://www2.le.ac.uk/departments/informatics/people/huiyu-zhou">Huiyu Zhou</a>
              <br>
              <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2020 
              <br>
              <a href="https://github.com/LongChenCV/SWIPENet">code</a>
              /
              <a href="https://arxiv.org/pdf/2005.11552.pdf">arXiv</a>
              <p></p>
              <p>Sample-WeIghted hyPEr Network (SWIPENet) for underwater small object detection.</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/dominos.png"></td>
            <td width="75%" valign="center">
              <a href="https://cordis.europa.eu/project/rcn/211947/en">Smart distribution grid: a market driven approach for the next generation of advanced operation models and services (DOMINOES)</a>
              <br>
              <br>
              <font>December 2020-June 2021</font>
            </td>
          </tr>
          
          <tr onmouseout="flyspin_stop()" onmouseover="flyspin_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div id='flyspin' class='hidden'><img src="images/Mosaicing2.gif"></div>
              <div id='flystill'>
                <a href="images/Mosaicing.gif"><img src="images/Mosaicingbegin.png"></a>
              </div>
              <script type="text/javascript">
                function flyspin_start() {
                  document.getElementById('flyspin').style.display = 'inline';
                  document.getElementById('flystill').style.display = 'none';
                }

                function flyspin_stop() {
                  document.getElementById('flyspin').style.display = 'none';
                  document.getElementById('flystill').style.display = 'inline';
                }
                flyspin_stop()
              </script>
            </td>
            <td width="75%" valign="center">
              <a>3D Reconstruction and Video Mosaicking with Applications to Fetoscopy</a>
              <br>
              <br>
              <font>July 2020</font>
              <br>
              <br>
              <font>Group project during UCL Medical Image Computing Summer School (MedICSS) 2020.</font>
              <br>
              <br>
              <a href="https://drive.google.com/file/d/1oJa2dJFrfyHq2mTDQ2JJryU2ItkJlMap/view?usp=sharing">Presentation Slide</a>
              /
              <a href="https://arxiv.org/pdf/1907.06543.pdf">Related Paper</a>
              /
              <a href="https://www.ucl.ac.uk/interventional-surgical-sciences/fetoscopy-placenta-data">Related Dataset</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/astrosat.png"></td>
            <td width="75%" valign="center">
              <a href="https://www.sprint.ac.uk/people/huiyu-joe-zhou/">Automated analysis of housing construction progress through remote sensing</a>
              <br>
              <br>
              <font>April 2020-April 2021</font>
              <br>
              <br>
              <font>Collabrative work with <a href="https://astrosat.net/">Stevenson Astrosat Ltd</a>.</font>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/pointcloudjd.png"></td>
            <td width="75%" valign="center">
              <a>Object detection in 3D point cloud</a>
              <br>
              <br>
              <font>Jan 2017-Sep 2018</font>
              <br>
              <br>
              <font>Industrial research and engineering work at</font> <a href="https://www.jdl.cn/">JD Logistics, JD.com.</a><font>Focused on vehicle, bicycle and pedestrian detection from 3D point cloud generated from LiDAR. Also focused on engineering work within point cloud data storge, data retrival, data access authentication development.</font>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching Assistant</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/uolcs.jpg"></td>
            <td width="75%" valign="center">
              <font color="#FF0000">2020-2023</font>
              <br>
              <font>CO1104 Computer Architecture</font>
              <br>
              <font>CO3102 Mobile and Web Applications</font>
              <br>
              <font>CO4105 Advanced C++ Programming</font>
              <br>
              <br>
              <font>CO3002 Analysis and Design of Algorithms</font>
              <br>
              <font>CO3099 Foundations of Cybersecurity</font>
              <br>
              <font>CO1109 Business and Financial Computing</font> 
              <br>
              <font>CO7218 Financial Services Information Systems</font>
              <br>
              <font color="#FF0000">2019-2020</font> 
              <br>
              <font>FS0023 STEM Foundation Year Lab-Physics</font> 
              <br>
              <font>CO3091 Computational Intelligence and Software Engineering</font>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Others</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="75%" valign="center">
              <font>I like traveling and photography. Here is my <a href="https://www.flickr.com/photos/192894210@N08/">flickr</a>.</font>
              <br>
              <br>
              <font>I also like sports, especially table tennis. I started to receive professional table tennis training from the age of 5, got into the school team, and gave up training in high school because of the college entrance examination. Overall it's great to play one or two games with friends to relieve stress.</font>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <font><a href="https://github.com/jonbarron/website">Website template</a> is from <a href="https://jonbarron.info/">Jon Barron</a>.<font> 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
